# US Congressional Tweets NLP Project
This project analyzes US Congressional tweets from June 2017 to July 2023 using NLP techniques. Extracting linguistic patterns, sentiments, and entities, it unveils insights into legislative communication trends.

## Introduction

This repository houses the code and data for the US Congressional Tweets NLP Project. The project aims to analyze and gain insights from tweets posted by members of the US Congress. By applying Natural Language Processing (NLP) techniques, the project aims to uncover linguistic patterns, sentiment analysis, and named entities present in the tweets.

## Data Source

The primary dataset used for this project is sourced from the "congresstweets" dataset, available on GitHub at [https://github.com/alexlitel/congresstweets](https://github.com/alexlitel/congresstweets). This dataset provides a comprehensive collection of tweets from US congressional members, spanning the period from June 2017 to July 2023.

## Project Structure

The repository is organized as follows:

- `Code/`: Contains all the Python scripts and Jupyter notebooks used for data preprocessing, analysis, and visualization.
- `Data/`: Houses the raw and processed data files. Due to size limitations, only a subset of the data may be provided here. The complete dataset can be obtained from the original source mentioned above.
- `Documents/`: Documentation files, including the README you're reading right now.

## Dependencies

Ensure you have the necessary dependencies installed to run the scripts in the `code/` directory. You can find the list of required packages in the `requirements.txt` file.

To install the required dependencies, run:

```bash
pip install -r requirements.txt